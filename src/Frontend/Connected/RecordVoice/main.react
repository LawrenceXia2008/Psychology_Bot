import React from "react";

import Button from "direct-core/UI/Button";

import { connect } from "react-redux";

import { bindActionCreators } from "redux";

import * as actions from "actions";

import FontAwesomeIcon from '@fortawesome/react-fontawesome'
import faPhone from '@fortawesome/fontawesome-free-solid/faPhone'
import faSlash from '@fortawesome/fontawesome-free-solid/faPhoneSlash'
import style from "style"

const audioCtx = new AudioContext();

const reader = new FileReader();

var processingTime = 0;

const SpeechRecognition = webkitSpeechRecognition;

class AutoCatchAudio extends React.Component {

  recognition = new SpeechRecognition()

  state = {}

  constructor( props ){
    super( props );
    this.recognition.continuous = true;
    this.recognition.interimResults = true;
    this.recognition.lang = "zh-CN";

    this.recognition.onresult = ev => {
      const { voice } = this.props;
      const length = ev.results.length;
      const res = ev.results[length - 2] || ev.results[0];
      if( res.isFinal ){
        this.setState({
          listening: false
        });
        this.recognition.stop();
        this.props.send({
          said: res[0].transcript
        })
        this.setState({
          said: res[0].transcript
        });
        fetch( "/api/getAnswer", {
          method: "POST",
          headers: {
            "Content-Type": "application/json"
          },
          body: JSON.stringify({ text: res[0].transcript })
        }).then( response => {
          response.json().then(
            json => {
              this.setState({
                response: json.activities[1].text
              });
              this.props.send({
                response: json.activities[1].text
              });
              return json.activities[1].text;
            }
          ).then( text => fetch("/api/textToVoice", {
            method: "post",
            headers: {
              "Content-Type": "application/json"
            },
            body: JSON.stringify({
              text,
              voice: voice + 1
            })
          }).then( response => response.json()).then( json => this.setURl( json.url ) ))
        });

      }
    }
  }

  start = () => {
    this.recognition.start();
    this.props.onStart();
    this.setState({
      listening: true
    });
  }

  stop = () => {
    this.recognition.stop();
    this.props.onEnd();
  }

  getAudio = ref => this.audio = ref;

  continuePlay = $ => {
    this.recognition.start();
    this.setState({
      listening: true
    });
  }

  setURl = url => {
    this.audio.src = url;
    this.audio.play();
  }

  handleChange = ( $, key ) => {
    this.props.selectVoice( key );
  }

  render(){
    const { response, said, listening } = this.state;
    return (
      <div className={style.btnWrap}>
        {
          listening ?
            <div style={{color:"white"}}>机器人正在聆听...</div>
          : null
        }
        <div
          onClick={this.start}
          className={style.startBtn}
        >
          <FontAwesomeIcon icon={faPhone} className={style.phoneIcon}/>
        </div>
        <audio
          ref={this.getAudio}
          onEnded={this.continuePlay}
          style={{
            display: "none"
          }}
        />
        <div
          onClick={this.stop}
          className={style.stopBtn}
        >
        <FontAwesomeIcon icon={faSlash} className={style.slashIcon} />
        </div>
      </div>
    );
  }
};

export default connect(
  state => ({
    voice: state.Audio.voice
  }),
  dispatch => bindActionCreators( actions , dispatch )
)(AutoCatchAudio);
